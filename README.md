# CAP6415_F25_project-Training-a-large-model-using-Unity-Perception-images
# Training a Large Model Using Unity Perception Images

## ðŸ§  Abstract
This project investigates how a large state-of-the-art (SOTA) model, **YOLOv8**, performs when trained and fine-tuned using **synthetic images generated by Unity Perception** and **real-world datasets**.  
Some object classes are underrepresented in real datasets, which leads to poor model generalization.  
To address this imbalance, we use **Unityâ€™s Perception package** to generate 3D synthetic images of these rare or missing objects under varied lighting, camera angles, and backgrounds.  
The resulting images and annotations are then used to **augment real datasets** and evaluate performance improvements in object detection tasks.

Our goal is to demonstrate that combining Unity-generated synthetic data with real data can significantly enhance model robustness and accuracy on underrepresented classes.

---

## âš™ï¸ Framework and Tools

- **Framework:** [Ultralytics YOLOv8](https://github.com/ultralytics/ultralytics)
- **Programming Language:** Python 3.8+
- **Synthetic Data Generation:** [Unity Perception Package](https://github.com/Unity-Technologies/com.unity.perception)
- **Real Dataset Source:** [COCO 2017](https://cocodataset.org/#download) subset from Kaggle (cup, bottle, chair, laptop, book classes)
- **Environment:** Jupyter Notebook or Python scripts

---

## ðŸ§© Problem Statement
Some object categories in large datasets are severely underrepresented, making it difficult for deep learning models to learn their features effectively.  
This project explores the impact of **synthetic data augmentation** â€” generated using Unityâ€™s 3D environment â€” on training performance and accuracy when compared with purely real-world data.

---

## ðŸ“Š Dataset Description

| Dataset | Source | Description | Size |
|----------|---------|-------------|------|
| **Real Dataset** | [COCO 2017 (subset)](https://www.kaggle.com/datasets/coco-dataset/coco-2017) | Contains real images of cups, bottles, chairs, laptops, and books. Used as baseline training data. | ~250 images |
| **Synthetic Dataset** | Generated with Unity Perception | Contains rendered 3D scenes of the same objects under various lighting, camera angles, and backgrounds. | ~250 images |
datasets/
â”œâ”€â”€ real/
â”‚ â”œâ”€â”€ images/{train,val}
â”‚ â””â”€â”€ labels/{train,val}
â””â”€â”€ synthetic/
â”œâ”€â”€ images/{train,val}
â””â”€â”€ labels/{train,val}

Each label file corresponds to an image and follows YOLO format:  
`class_id x_center y_center width height`

---

## ðŸ§± Project Structure

unity-perception-model/
â”œâ”€â”€ datasets/
â”‚ â”œâ”€â”€ real/
â”‚ â””â”€â”€ synthetic/
â”œâ”€â”€ data_yaml/
â”‚ â”œâ”€â”€ real.yaml
â”‚ â””â”€â”€ synthetic.yaml
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ train.py
â”‚ â”œâ”€â”€ evaluate.py
â”‚ â””â”€â”€ utils/
â”œâ”€â”€ results/
â”‚ â”œâ”€â”€ accuracy_plots/
â”‚ â””â”€â”€ sample_predictions/
â””â”€â”€ README.md

---

## ðŸ§° Installation

### 1ï¸âƒ£ Clone the repository
```bash
git clone https://github.com/yourusername/unity-perception-model.git
cd unity-perception-model
 2 Create virtual environment
python -m venv venv
source venv/bin/activate   # for macOS/Linux
venv\Scripts\activate      # for Windows
3ï¸âƒ£ Install dependencies
pip install -r requirements.txt
4ï¸âƒ£ Dependencies include:
torch >= 2.0
torchvision
ultralytics
opencv-python
matplotlib
numpy
pillow

